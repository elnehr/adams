{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb90b5a8",
   "metadata": {},
   "source": [
    "# Exercise NLP pipeline\n",
    "You are already familiar with building predictive models on tabular data. In tabular data, you have a feature matrix X, and a target vector Y. Given this data structures, you can apply learning algorithms like neural networks or random forest to learn the relationship between X and Y. In this exercise, you are provided a data set of movie reviews and your goal is to build a classifier predicting whether a review is positive or negative (this task is called sentiment classification). Hence, you have a prediction problem with a binary target Y, which is nothing new for you. What is new for you in this exercise, is that you need to deal with text data instead of tabular data. With text data, you need to process the data to obtain the required feature matrix X. This processing of data is what we call the \"NLP pipeline\". \n",
    "\n",
    "In this exercise, you will need to set up a NLP pipeline. You are provided a data set of movie reviews, where each sample contains a review (just a string cell). To obtain a feature matrix, each samples string cell needs to be transformed into a feature vector $x$. This process is called vectorization. There are multiple possible vectorization procedures. Today, you will implement a bag-of-words model for feature extraction. This feature extraction process involves two steps:\n",
    "1. Vocabulary building\n",
    " * Tokenization: Transforming a review, which is a single string at the beginning, into a vector of strings (tokens).\n",
    " * Cleaning and compressing techniques: Reducing the number of distinct tokens. E.g. correcting misspelling of words or transforming all letters to lower case prevents that the same word appears in multiple ways of spelling. Additionaly, similar words (e.g. different forms of a verb) can be united into a single token. \n",
    " * Building a bag-of-words: a vector whose length corresponds exactly to the number of different tokens. Each token is assigned the position within the vector. \n",
    " \n",
    "2. Feature creation based on term frequency: Each review gets transformed into a feature vector $x$. The length of the feature vector corresponds to the length of the bag-of-words vector, created in step 1. An element $x_{j}$ of the feature vector is calculated by a frequency measure, measuring how frequently token $j$ from the bag-of-words vector occurs in the review. \n",
    "\n",
    "The first code cells provide required packages and load the review data set, which you will use for the exercise. Then the exercise begins. In the exercise, you will build the most simple NLP pipeline, which means that you go through steps 1 and 2 of the NLP pipeline, but you skip the \"cleaning and compressing\" part of step 1. This simple NLP pipeline provides you a feature matrix X (which is possibly not ideal). You will use this feature matrix to build and evaluate a predictive model.\n",
    "\n",
    "In the tutorial, we will extend your NLP pipeline by including the cleaning and compressing techniques (according techniques are also covered in detail in the demo notebook \"nlp_foundations.ipynb\"). This will lead to another feature matrix X. We will build another predictive model on this new feature matrix X and compare the performance to the model build by the simplified NLP pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec2f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6885cd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Remeber to adjust the path so that it matches your environment\n",
    "df = pd.read_csv(\"IMDB-50K-Movie-Review.zip\", sep=\",\", encoding=\"ISO-8859-1\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5424923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get to know the data\n",
    "print(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2590c955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    5028\n",
       "negative    4973\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only use the first 10000 observations to reduce run time.\n",
    "df = df.loc[0:10000,:]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)  # dropping the index prohibits a reidentification of the cases in the original data frame\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4fe5cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map label\n",
    "df['sentiment'] = df['sentiment'].map({'positive' : 1, 'negative': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf198df3",
   "metadata": {},
   "source": [
    "## Exercise (simple NLP pipeline):\n",
    "You need to transform the text data, contained in the column df[\"review\"], such that it is suitable as a feature matrix X, which you need for predictive model building. This means in detail: <br>\n",
    "a) Create a list \"reviews_tokenized\", where each element corresponds to a string vector, representing a review. Use NLTK's word_tokenize() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c499afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcfd67a6",
   "metadata": {},
   "source": [
    "b) Split the review data (reviews_tokenized) as well as the target df['sentiment'] in training and test sets. Use 80% of the data for training. Use sklearn's train_test_split() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b395c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11968263",
   "metadata": {},
   "source": [
    "c) Now, we need to set up a vocabulary for all tokens and apply this vocabulary to obtain feature vectors $x$. We do this using sklearn's TfidfVectorizer. We provide the code to set up the vectorizer below. You need to apply the vectorizer to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a33159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc       \n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = dummy_fun,\n",
    "    preprocessor = dummy_fun,\n",
    "    token_pattern = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14705493",
   "metadata": {},
   "source": [
    "The TfidfVectorizer did multiple steps at once. To better understand how it works, you should examine the results step by step. <br>\n",
    "d) Examine the vocabulary it created: How many tokens does it include? Which tokens are included? Would it maybe be better to leave some of these tokens out to reduce the dimension of the vocabulary and the derived feature matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8daa916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a26d6fb5",
   "metadata": {},
   "source": [
    "e) Let's recap how feature vectores are generated from this vocabulary. The basic idea of bag-of-words based feature extraction is to generate for each token in the vocabulary a column in the feature matrix X. For an observation $i$ (corresponding to a single review), the entry $X_{i,j}$ of the feature matrix would be 1 if the review contains the token of column $j$ and 0 otherwise. There are some variations to this approach. The Tfidf approach, which we apply in this exercise, encodes $X_{i,j}$ not as 1 if the review contains token $j$ but as the occurence frequency of token $j$ in the review divided by the occurence frequency of token $j$ in the whole document (all reviews of the data set combined). Have a look at the matrix, which the TfidfVectorizer created.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9972e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf162233",
   "metadata": {},
   "source": [
    "f) Fit a ridge regression classifier and evaluate the accuracy of the predictions on the training and test set. We provide the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50877e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RidgeClassifier(random_state=42, alpha=0.8)\n",
    "classifier.fit(reviews_tr, y_train)\n",
    "pred_test = classifier.predict(reviews_ts)\n",
    "pred_train = classifier.predict(reviews_tr)\n",
    "print(metrics.accuracy_score(y_train, pred_train))\n",
    "print(metrics.accuracy_score(y_test, pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
